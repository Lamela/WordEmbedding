{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1.La présentation de bases de données existantes en chinois"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Nous avons trouvé un corpus chinois. Le sujet de corpus est la nouvelle. Donc nous allons d'abord présenter le corpus dans le notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('news_fasttext_train.txt') as f:\n",
    "    f_news = f.readlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "英媒称 威廉 王子 圣诞节 前 将 宣布 订婚   　 　 中新网 11 月 8 日电   据 香港 《 文汇报 》 报道 ， 英媒称 英国 威廉 王子 和 女友 凯蒂 将 于 圣诞节 前 宣布 订婚 ， 并 于 明年 7 月 23 日拉埋 天窗 ， 结束 8 年 爱情 长跑 ， 并 计划 婚后 生儿育女 ， 组织 幸福家庭 。   　 　 报道 指 ， 28 岁 的 凯蒂 预定 与 王室 成员 一起 ， 在 诺福克郡 桑德灵 厄姆堡 欢度 圣诞节 ， 但 她 须 先 与 威廉 订婚 才 可 获邀 出席 。 消息人士 透露 ， 一切 安排 都 是 为 两人 明年 的 婚事 铺路 ， 而且 “ 进展 迅速 ” 。   　 　 两人 决定 在 温莎堡 乔治 教堂 低调 成婚 ， 这里 也 是 王储 查尔斯 和 卡米拉 2005 年 结婚 之 处 。 据悉 英女王 也 希望 在 政府 紧缩 开支 时 ， 避免 婚事 太 铺张浪费 。   　 　 传媒 本周 拍摄 到 凯蒂 父母 在 女王 位于 苏格兰 的 巴尔 莫 勒尔 堡 打猎 ， 更 获 女王 批准 在 附近 一间 王宫 住宿 ， 令 威廉 、 凯蒂 快 将 宣布 婚事 的 传闻 甚嚣尘上 。   　 　 另外 ， 女王 跟随 威廉 、 哈里 王子 和 其他 年轻 王室 成员 ， 正式 加入 大热 社交 网站 facebook ， 成立 王室 官方 页面 ， 公布 王室 活动 、 照片 、 影片 、 新闻 和 发言 。 facebook 用家 对 页面 点击 “ 赞 ” ( like ) ， 就 可 定期 收到 活动 更新 。   　 　 中新网 11 月 8 日电   据 香港 《 文汇报 》 报道 ， 英媒称 英国 威廉 王子 和 女友 凯蒂 将 于 圣诞节 前 宣布 订婚 ， 并 于 明年 7 月 23 日拉埋 天窗 ， 结束 8 年 爱情 长跑 ， 并 计划 婚后 生儿育女 ， 组织 幸福家庭 。   　 　 报道 指 ， 28 岁 的 凯蒂 预定 与 王室 成员 一起 ， 在 诺福克郡 桑德灵 厄姆堡 欢度 圣诞节 ， 但 她 须 先 与 威廉 订婚 才 可 获邀 出席 。 消息人士 透露 ， 一切 安排 都 是 为 两人 明年 的 婚事 铺路 ， 而且 “ 进展 迅速 ” 。   　 　 两人 决定 在 温莎堡 乔治 教堂 低调 成婚 ， 这里 也 是 王储 查尔斯 和 卡米拉 2005 年 结婚 之 处 。 据悉 英女王 也 希望 在 政府 紧缩 开支 时 ， 避免 婚事 太 铺张浪费 。   　 　 传媒 本周 拍摄 到 凯蒂 父母 在 女王 位于 苏格兰 的 巴尔 莫 勒尔 堡 打猎 ， 更 获 女王 批准 在 附近 一间 王宫 住宿 ， 令 威廉 、 凯蒂 快 将 宣布 婚事 的 传闻 甚嚣尘上 。   　 　 另外 ， 女王 跟随 威廉 、 哈里 王子 和 其他 年轻 王室 成员 ， 正式 加入 大热 社交 网站 facebook ， 成立 王室 官方 页面 ， 公布 王室 活动 、 照片 、 影片 、 新闻 和 发言 。 facebook 用家 对 页面 点击 “ 赞 ” ( like ) ， 就 可 定期 收到 活动 更新 。    \t__label__affairs\n",
      "\n",
      "趣味 测试 ： 你 像 NBA 哪位 明星 球员 ( 图 )   　 　 独家 撰稿 ： 海衣 苍朵 十 & 白鸟   　 心理 测试 征稿启事   　 　 姚明 恢复 训练 ， 火箭 退出 前八 ， 麦蒂去 了 尼克斯 ～ NBA 风云变幻 是 活生生 的 的 戏剧 。 我们 都 活 在 这 滑稽 的 世界 上 ， 告诉 自己 有时 不惜 逆 潮流 而 为 之 ， 就 像 NBA 的 明星 球员 ， 即使 明白 规则 ， 也 要 活出 个 自我 ！   　 　 你 像 NBA 哪位 明星 球员 ？   　 　 ( 本 测试 不 超过 12 道题 ， 4 个 答案 ， 系统 自动 跳转 。 仅供 娱乐 ， 非专业 心理 指导 。 )    \t__label__constellation\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "for i in range(2):\n",
    "    print(f_news[i*10000])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Nous avons vu, dans le text, chaque ligne du text contient une nouvelle. Tous les mots chinois ont été séparés par un espace. À la fin de chaque ligne, elle a marqué une étiquette du sujet. Les charactères liées sont des mots en chinois."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous allons maintenant construire le jeu de données.\n",
    "- D'abord, nous allons éliminer les mots non chinois et spérarer les labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "def filter(s):\n",
    "    #s = s.decode(\"utf-8\")\n",
    "    filtrate = re.compile(u'[^\\u4E00-\\u9FA5]')\n",
    "    res = filtrate.sub(r' ', s)\n",
    "    return res\n",
    "datasets = {}\n",
    "x = []\n",
    "y = []\n",
    "for i in range(len(f_news)):\n",
    "    temp = filter(f_news[i])\n",
    "    words = temp.split()\n",
    "    x.append(words)\n",
    "    label = f_news[i].split(\" \")[-1].replace(\"\\n\", \"\").split(\"_\")[-1]\n",
    "    y.append(label)\n",
    "    \n",
    "datasets['data'] = x\n",
    "datasets['target'] = y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "with open('news_split_pure.json', 'w') as f:\n",
    "    json.dump(datasets, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "dataframe = pd.DataFrame(datasets)\n",
    "dataframe.to_csv(\"newz_split_pure.csv\",index=False,sep=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "del(datasets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time used to train model: 18.264241456985474\n",
      "Time used to test model: 8.067509412765503\n",
      "0.904565198463756\n",
      "0.904565198463756\n"
     ]
    }
   ],
   "source": [
    "import fasttext\n",
    "import time\n",
    "# Skipgram model\n",
    "tic = time.time()\n",
    "clf = fasttext.supervised('news_fasttext_train.txt', 'model')\n",
    "toc = time.time()\n",
    "print('Time used to train model: ' + str(toc - tic))\n",
    "\n",
    "tic = time.time()\n",
    "res = clf.test('news_fasttext_test.txt')\n",
    "toc = time.time()\n",
    "print('Time used to test model: ' + str(toc - tic))\n",
    "\n",
    "print(res.precision)\n",
    "print(res.recall)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time used to train cbow word embedding: 236.83155059814453\n",
      "189984\n"
     ]
    }
   ],
   "source": [
    "tic = time.time()\n",
    "model = fasttext.cbow('news_fasttext_train.txt', 'model')\n",
    "toc = time.time()\n",
    "print('Time used to train cbow word embedding: ' + str(toc - tic))\n",
    "\n",
    "print(len(model.words)) # list of words in dictionary\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n",
      "[-0.05577888339757919, 0.5747898817062378, 0.22692202031612396, 0.4946122169494629, -0.18957051634788513, -0.17648553848266602, -0.39239057898521423, -0.0555281937122345, 0.18335533142089844, 0.11815828084945679, 0.56656813621521, -0.22199392318725586, 0.5065208673477173, 0.40128207206726074, 0.43143612146377563, 0.4246213436126709, -0.277787446975708, -0.22947901487350464, 0.45027220249176025, 0.1363823115825653, -0.2217646837234497, 0.192704975605011, -0.09822869300842285, 0.006437172647565603, 0.1444288194179535, 0.27505701780319214, -0.3348937928676605, -0.023767095059156418, -0.2854846119880676, -0.8086239099502563, -0.09918409585952759, -0.029884761199355125, 0.1913653463125229, -0.2349591702222824, -0.3739858567714691, 0.0973408967256546, 0.31533583998680115, -0.4581424593925476, -0.2626631557941437, 0.11524378508329391, 0.3455769419670105, -0.028281312435865402, -0.29140642285346985, -0.21107324957847595, 0.47397279739379883, -0.5091606974601746, -0.9433766603469849, 0.7063651084899902, -0.6494448184967041, -0.4895438849925995, 0.5994689464569092, 0.11583619564771652, -0.0841178447008133, -0.3619289994239807, -0.20883285999298096, 0.2988636791706085, -0.08405117690563202, 0.11775737255811691, 0.6176376342773438, 0.16744780540466309, 0.3242085874080658, 0.27183616161346436, 0.0873773917555809, 0.7539441585540771, 0.12515044212341309, 0.054456811398267746, -0.42738014459609985, 0.20416554808616638, 0.17918089032173157, -0.13627362251281738, -0.3536536395549774, -0.4297832250595093, -0.29717183113098145, -0.3300507068634033, 0.3676673173904419, -0.2739403247833252, -0.6043366193771362, -0.42655473947525024, -0.17440664768218994, -0.3325427770614624, -0.33102184534072876, 0.3008868992328644, -0.06647499650716782, 0.13894984126091003, -0.011803041212260723, 0.3114173710346222, 0.19143395125865936, 0.47240447998046875, 0.0121158417314291, 0.17692407965660095, -0.27465081214904785, -0.11435313522815704, 0.9519168734550476, -0.15112298727035522, 0.6985753774642944, -0.27682527899742126, 0.5423479080200195, -0.1768427938222885, 0.3599781394004822, 0.1936415135860443]\n"
     ]
    }
   ],
   "source": [
    "print('大英国' in model.words)\n",
    "print(model['大英国'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17.634902570280985\n",
      "20.134612434390935\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "print(np.linalg.norm((model['中国'], model['北京'])))\n",
    "\n",
    "print(np.linalg.norm((model['德国'], model['伦敦'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
