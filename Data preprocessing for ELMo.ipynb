{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import re\n",
    "#import fasttext\n",
    "import time\n",
    "import multiprocessing\n",
    "from gensim.models import Word2Vec\n",
    "from gensim.models.word2vec import LineSentence\n",
    "import pandas as pd\n",
    "import subprocess\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import itertools\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['数码 通及 合 和 实业 回购 股份 ', ' 新浪 财经 讯 12 月 01 日 消息 ， 数码 通 ( 00315 - HK ) 申报 回购 33 万股 ， 每股 作价 5.12 元至 5.2 元 ， 涉资 170.41 万元 。 ', ' 合 和 实业 ( 00054 - HK ) 申报 回购 1 , 500 股 ， 每股 作价 24.3 元 ， 涉 3.65 万元 。已有 _ COUNT _ 条 评论 我要 评论']\n"
     ]
    }
   ],
   "source": [
    "f_news = []\n",
    "\n",
    "with open('datasets/news_fasttext_train.txt') as f:\n",
    "    for line in f:\n",
    "        f_news.append(f.readline())\n",
    "\n",
    "print(f_news[-2].split('\\t')[0].replace('\\xa0', '').replace('  ', '').split('\\u3000 \\u3000'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('datasets/news_fasttext_train.txt') as origin:\n",
    "    with open('datasets/news_raw_nolabel.txt', 'w') as f:\n",
    "        for line in origin:\n",
    "            temp = line.split('\\t')[0].replace('\\xa0', '').replace('  ', '').split('\\u3000 \\u3000')\n",
    "            for i in range(len(temp)):\n",
    "                temp[i] = temp[i].replace('\\u3000', '')\n",
    "                f.write(\"{}\\n\".format(temp[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of tokens : 62014273\n"
     ]
    }
   ],
   "source": [
    "tokens = 0\n",
    "i = 0\n",
    "with open('datasets/news_raw_nolabel.txt', 'r') as f:\n",
    "    for line in f:\n",
    "        tokens += len(line.split())\n",
    "\n",
    "print(\"Total number of tokens : \" + str(tokens))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('pre_trained_vectors/raw_300/ft_raw_skipgram_300.vec', 'r') as f:\n",
    "    with open('pre_trained_vectors/raw_300/ft_5_vocab.txt', 'w+') as file:\n",
    "        file.write('<S>\\n</S>\\n')\n",
    "        _ = f.readline()\n",
    "        for line in f:\n",
    "            temp = line.split()\n",
    "            file.write('{}\\n'.format(temp[0]))            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('pre_trained_vectors/raw_300/raw_5_vocab.txt', 'r') as f:\n",
    "    with open('pre_trained_vectors/raw_300/glove_5_vocab.txt', 'w+') as file:\n",
    "        file.write('<S>\\n</S>\\n<UNK>\\n')\n",
    "        for line in f:\n",
    "            temp = line.split()\n",
    "            file.write('{}\\n'.format(temp[0]))  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Transfer the txt vectors to hdf5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "could not broadcast input array from shape (299) into shape (300)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-18-923a6205ee5b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0mtemp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mline\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m         \u001b[0mvec\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtemp\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m         \u001b[0membeddings\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvec\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m         \u001b[0mi\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: could not broadcast input array from shape (299) into shape (300)"
     ]
    }
   ],
   "source": [
    "import h5py\n",
    "import numpy as np\n",
    "\n",
    "n_token = 0\n",
    "with open('/home/chenxin/WordEmbedding/pre_trained_vectors/raw_300/ft_5_vocab.txt', 'r') as f:\n",
    "    for line in f:\n",
    "        n_token += 1\n",
    "        \n",
    "embeddings = np.zeros((n_token, 300))\n",
    "i = 2\n",
    "with open('/home/chenxin/WordEmbedding/pre_trained_vectors/raw_300/ft_raw_skipgram_300.vec', 'r') as f:\n",
    "    _ = f.readline()\n",
    "    for line in f:\n",
    "        temp = line.split()\n",
    "        vec = np.array(temp[1:])\n",
    "        embeddings[i] = vec\n",
    "        i += 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('datasets/news_raw_nolabel.txt', 'r') as f:\n",
    "    for line in f:\n",
    "        if '\\u3000' in line:\n",
    "            print(str(line))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "could not broadcast input array from shape (299) into shape (300)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-23-046207612d69>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtemp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m         \u001b[0mvec\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtemp\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m         \u001b[0membeddings\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvec\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m         \u001b[0mi\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: could not broadcast input array from shape (299) into shape (300)"
     ]
    }
   ],
   "source": [
    "i = 2\n",
    "with open('/home/chenxin/WordEmbedding/pre_trained_vectors/raw_300/ft_5_vocab.txt', 'r') as f:\n",
    "    for line in f:\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b'\\xe2\\x80\\x83 0.86293 0.22522 -0.79965 0.4992 0.1027 0.22174 -0.40173 -0.31652 -0.048179 0.052495 0.73216 1.0513 -0.030755 0.32309 -0.53907 0.68331 0.098927 -0.60278 -0.12234 -0.22029 -0.0085215 0.63536 0.35803 0.57202 -0.63249 0.1675 0.24349 0.26912 0.2611 0.23714 0.0058989 0.067044 -0.50479 -0.33798 -0.63998 0.50098 -0.061128 -0.49068 -0.2643 -0.10708 -0.44271 -0.13776 -0.49906 0.36042 -0.057518 0.17255 0.33322 -0.65009 -0.68437 0.27279 -0.5577 -0.13477 0.26014 -0.29837 0.58462 -0.25372 0.068013 -0.5997 0.15197 -0.39636 0.20379 -0.01857 0.047061 -0.038932 0.11172 0.0085653 0.099622 -0.043242 -0.040492 -0.69145 0.20698 0.19222 0.0027948 -0.11879 -0.38068 -0.62065 0.86715 0.60022 -0.37306 -0.01661 -0.1803 0.31454 0.16876 -0.625 0.25383 0.078141 -0.14337 -0.36476 -0.19892 0.061985 -0.28267 0.3232 0.55201 0.0040214 0.42924 -0.15917 -0.71128 -0.063316 0.42834 0.070467 0.28878 -0.14301 -0.047324 0.0095609 -0.60631 0.72252 0.7909 -0.020283 0.8824 -0.15433 0.35441 0.31628 -0.4513 0.037693 -0.019493 0.036969 -0.32434 -0.13194 0.48069 -0.026237 0.26353 -0.26356 -0.34256 0.28756 0.12087 -0.1589 0.15864 0.15681 0.33214 0.3655 -0.39715 -0.26679 -0.45393 0.34561 -1.1978 -0.16046 0.075224 0.061153 0.19209 -0.20266 0.0068072 -0.070476 0.1425 -0.078954 0.91516 -0.16354 0.15166 0.22249 0.044372 -0.36339 -0.021014 0.60799 0.20156 0.080106 -0.22216 -0.076567 0.41739 0.048293 -0.26474 -0.19484 -0.057846 0.1568 -0.033077 0.27276 0.39217 0.21526 0.27234 -0.34595 -0.63623 -0.081628 0.10307 0.29107 -0.52592 -0.15152 -0.024204 0.18054 -0.010763 0.58289 -0.035465 0.11611 0.62327 -0.19777 -0.0054645 -0.3445 -0.12467 -0.23864 0.78794 -0.39106 -0.078041 0.13855 -0.095765 -0.12347 0.36205 -0.0058029 0.66921 -0.4997 -0.32325 -0.3103 -0.5014 0.26407 0.22566 0.27955 0.26619 -0.26694 -0.12302 -0.27009 -0.053242 -1.1251 -0.43915 0.59214 -0.29749 0.1073 -0.76695 -0.2079 0.017728 -0.21693 0.27916 0.11955 -0.51308 0.85049 -0.56262 0.19696 -0.40597 -0.69466 0.59395 0.052039 0.49312 0.078444 0.24234 -0.13538 0.095835 0.040422 0.5262 -0.015741 0.47371 0.066642 0.36461 -0.85126 0.29105 -0.36614 -0.21311 0.021857 0.17053 -0.37846 -0.36837 0.094086 -0.88268 0.38075 -0.24065 0.055837 0.06799 0.58914 0.10119 0.50996 -0.74402 0.02646 0.17083 -0.32219 -0.28521 -0.015424 -0.074091 -0.22191 0.20797 0.4426 -0.29835 -0.21542 0.11623 0.25737 0.6262 -0.46624 0.028226 -0.1338 0.87763 0.70182 0.044396 0.48355 0.12585 0.060065 0.63784 -0.2406 -0.0058957 -0.067459 0.36793 -0.23232 -0.48728 0.59165 0.62579 -0.88313 0.063947 -0.62278 -0.18591 -0.39536 -0.71351 -0.61976 -0.63165 0.30647 0.077087 -0.37809 0.19572 -0.20276 \\n'\n"
     ]
    }
   ],
   "source": [
    "print(line.encode('utf-8'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
