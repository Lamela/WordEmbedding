{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ast\n",
    "import os\n",
    "import keras\n",
    "from keras.layers import Dense, Embedding, Input\n",
    "from keras.layers import GRU, Dropout, MaxPooling1D, Conv1D, Flatten, LSTM\n",
    "from keras.models import Model\n",
    "import numpy as np\n",
    "import itertools\n",
    "from keras.utils import np_utils, Sequence\n",
    "from sklearn.metrics import classification_report, precision_recall_fscore_support, accuracy_score\n",
    "from sklearn import preprocessing\n",
    "from keras.preprocessing import text, sequence\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "from plot_util import plot_confusion_matrix\n",
    "import time\n",
    "import h5py\n",
    "%matplotlib inline\n",
    "\n",
    "# Model parameters\n",
    "MAX_FEATURES = 256404\n",
    "MAX_TEXT_LENGTH = 2000\n",
    "EMBED_SIZE  = 300\n",
    "BATCH_SIZE = 64\n",
    "EPOCHS = 2\n",
    "VALIDATION_SPLIT = 0.1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous définissons la fonction pour lire le jeu de données et faire le découpage d'apprentissage et test. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_datasets(data_paths, test_size):\n",
    "    x = []\n",
    "    y = []\n",
    "    for data_path in data_paths:\n",
    "        with open(data_path, 'r') as f:\n",
    "            for line in f:\n",
    "                temp = line.split('__label__')\n",
    "                x.append(temp[0])\n",
    "                y.append(temp[1].replace('\\n', ''))\n",
    "            \n",
    "    x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=test_size)\n",
    "    print('Dataset splited.')\n",
    "    return x_train, x_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pour construire le pipeline, nous allons d'abord définir des fonctions pour pré-traiter les données.\n",
    "\n",
    "Nous allons tokenizer les données et nous mettrons les données et les labels au format propre pour le réseau de neurones. Les labels seront transmis aux vecteurs one-hot. Les données seront tokenizées et mises à la même longueur. Nous coupons les exemples trop longs et nous utilisons zero-padding pour les exemples courts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_train_test(train_raw_text, test_raw_text):\n",
    "    \n",
    "    tokenizer = text.Tokenizer(num_words=MAX_FEATURES)\n",
    "\n",
    "    tokenizer.fit_on_texts(list(train_raw_text))\n",
    "    word_index = tokenizer.word_index\n",
    "    train_tokenized = tokenizer.texts_to_sequences(train_raw_text)\n",
    "    test_tokenized = tokenizer.texts_to_sequences(test_raw_text)\n",
    "    return sequence.pad_sequences(train_tokenized, maxlen=MAX_TEXT_LENGTH), \\\n",
    "           sequence.pad_sequences(test_tokenized, maxlen=MAX_TEXT_LENGTH), \\\n",
    "           word_index\n",
    "\n",
    "\n",
    "def class_str_2_ind(x_train, x_test, y_train, y_test):\n",
    "    print('Converting data to trainable form...')\n",
    "    le = preprocessing.LabelEncoder()\n",
    "    n_out = len(CLASSES_LIST)\n",
    "    le.fit(CLASSES_LIST)\n",
    "    y_train = le.transform(y_train)\n",
    "    y_test = le.transform(y_test)\n",
    "    train_y_cat = np_utils.to_categorical(y_train, n_out)\n",
    "    x_vec_train, x_vec_test, word_index = get_train_test(x_train, x_test)\n",
    "    print('Number of training examples: ' + str(len(x_vec_train)))\n",
    "    print('Number of test examples: ' + str(len(x_vec_test)))\n",
    "    \n",
    "    return x_vec_train, x_vec_test, y_train, y_test, train_y_cat, word_index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous définissons la fonction pour lire les vecteurs de mots pré-appris. Nous construissons aussi la matrice d'entrée depuis x_train et les vecteurs de mots. Cette partie est basé sur le [tutoriel de Keras](https://blog.keras.io/using-pre-trained-word-embeddings-in-a-keras-model.html) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_embedding_index(vectors_file_path):\n",
    "    embeddings_index = {}\n",
    "    with open(vectors_file_path, 'r') as f:\n",
    "        first_line = f.readline()\n",
    "        #print(first_line)\n",
    "        for line in f:\n",
    "            values = line.split()\n",
    "            word = values[0]\n",
    "            coefs = np.asarray(values[1:], dtype='float32')\n",
    "            embeddings_index[word] = coefs\n",
    "            \n",
    "    print('Found %s word vectors.' % len(embeddings_index))\n",
    "    \n",
    "    return embeddings_index\n",
    "\n",
    "\n",
    "def get_embedding_matrix(word_index, embedding_index):\n",
    "    print('Building embedding matrix...')\n",
    "    embedding_matrix = np.zeros((len(word_index) + 1, EMBED_SIZE))\n",
    "    for word, i in word_index.items():\n",
    "        embedding_vector = embedding_index.get(word)\n",
    "        if embedding_vector is not None:\n",
    "            # words not found in embedding index will be all-zeros.\n",
    "            embedding_matrix[i] = embedding_vector\n",
    "    print('Embedding matrix built.')        \n",
    "    return embedding_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous définissons un modèle de classification de texte avec une couche de Conv1D et une couche de Dense. Nous pouvons utiliser les vecteurs de mots pré-appris. Le modèle est basé sur le [TP de M. Kermorvant](https://gitlab.com/kermorvant/nlp-labs) et https://github.com/gaussic/text-classification-cnn-rnn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model(embedding_matrix, word_index, print_sum=True):\n",
    "\n",
    "    inp = Input(shape=(MAX_TEXT_LENGTH,))\n",
    "\n",
    "    model = Embedding(len(word_index) + 1,\n",
    "                      EMBED_SIZE,\n",
    "                      weights=[embedding_matrix],\n",
    "                      input_length=MAX_TEXT_LENGTH,\n",
    "                      trainable=False)(inp)\n",
    "    \n",
    "    #model = Dropout(0.2)(model)\n",
    "    model = Conv1D(filters=32, kernel_size=5, padding='same', activation='relu')(model)\n",
    "    model = Dropout(0.5)(model)\n",
    "    model = MaxPooling1D(pool_size=2)(model)\n",
    "    #model = Conv1D(filters=32, kernel_size=3, padding='same', activation='relu')(model)\n",
    "    #model = Dropout(0.5)(model)\n",
    "    #model = MaxPooling1D(pool_size=2)(model)\n",
    "    model = Flatten()(model)\n",
    "    model = Dense(512, activation='relu')(model)\n",
    "    model = Dropout(0.5)(model)\n",
    "    model = Dense(11, activation=\"softmax\")(model)\n",
    "    model = Model(inputs=inp, outputs=model)\n",
    "    \n",
    "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    if print_sum:\n",
    "        model.summary()\n",
    "    return model\n",
    "\n",
    "\n",
    "def train_fit_predict(model, x_train, x_test, y_train):\n",
    "    \n",
    "    model.fit(x_train, y_train,\n",
    "              batch_size=BATCH_SIZE,\n",
    "              epochs=EPOCHS, verbose=1)\n",
    "\n",
    "    return model.predict(x_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous plottons la matrice de confusion, code basé sur [l'exemple de sklearn](http://scikit-learn.org/stable/auto_examples/model_selection/plot_confusion_matrix.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_conf_mat(y_test, y_predicted):\n",
    "    conf_mat = confusion_matrix(y_test, y_predicted)\n",
    "    plt.figure(figsize=(10,10))\n",
    "    plt.subplot(121)\n",
    "    plot_confusion_matrix(conf_mat, CLASSES_LIST, title='Confusion matrix, without normalization')\n",
    "    plt.subplot(122)\n",
    "    plot_confusion_matrix(conf_mat, CLASSES_LIST, normalize=True, title='Normalized confusion matrix')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous construissons le pipeline pour evaluer la qualité des vecteurs de mots."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluation(vectors_file_path, print_sum=True, plot_mat=True):\n",
    "    embedding_index = get_embedding_index(vectors_file_path)\n",
    "    embedding_matrix = get_embedding_matrix(word_index, embedding_index)\n",
    "    print('Building model...')\n",
    "    model = get_model(embedding_matrix, word_index, print_sum=print_sum)\n",
    "    y_predicted = train_fit_predict(model, x_vec_train, x_vec_test, train_y_cat).argmax(1)\n",
    "    print(\"Test Accuracy:\", accuracy_score(y_test, y_predicted))\n",
    "    if plot_mat:\n",
    "        plot_conf_mat(y_test, y_predicted)\n",
    "    return accuracy_score(y_test, y_predicted)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Maintenant, nous allons lire le jeu de données *[news_fastexttext_test.txt](https://drive.google.com/open?id=1psrAH5heISv3t2xuB4YKxUCvsUN6yU6C)* et *[news_less_category.txt](https://drive.google.com/open?id=11kUgD4HhqRqhEhS_6yTx_QOXKCWGF3U8)*, puis faire le découpage afin d'obtenir le jeu de données d'apprentissage utilisé et le jeu de données de test utilisé."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset splited.\n",
      "Label categories: ['affairs' 'economic' 'edu' 'ent' 'fashion' 'game' 'home' 'house'\n",
      " 'science' 'sports' 'stock']\n",
      "Converting data to trainable form...\n",
      "Number of training examples: 192022\n",
      "Number of training examples: 21336\n"
     ]
    }
   ],
   "source": [
    "data_paths = ['datasets/news_less_category.txt', 'datasets/news_fasttext_test.txt']\n",
    "test_size = 0.1\n",
    "x_train, x_test, y_train, y_test = split_datasets(data_paths, test_size)\n",
    "CLASSES_LIST = np.unique(y_train)\n",
    "print('Label categories: ' + str(CLASSES_LIST))\n",
    "x_vec_train, x_vec_test, y_train, y_test, train_y_cat, word_index = class_str_2_ind(x_train, x_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "D'abord, nous faisons un exemple d'évaluations en utilisant *word2vec_skip*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 182712 word vectors.\n",
      "Building embedding matrix...\n",
      "Embedding matrix built.\n",
      "Building model...\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Fetch argument <tf.Variable 'embedding_2/embeddings:0' shape=(499368, 300) dtype=float32_ref> cannot be interpreted as a Tensor. (Tensor Tensor(\"embedding_2/embeddings:0\", shape=(499368, 300), dtype=float32_ref) is not an element of this graph.)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, fetches, contraction_fn)\u001b[0m\n\u001b[1;32m    281\u001b[0m         self._unique_fetches.append(ops.get_default_graph().as_graph_element(\n\u001b[0;32m--> 282\u001b[0;31m             fetch, allow_tensor=True, allow_operation=True))\n\u001b[0m\u001b[1;32m    283\u001b[0m       \u001b[0;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mas_graph_element\u001b[0;34m(self, obj, allow_tensor, allow_operation)\u001b[0m\n\u001b[1;32m   3477\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3478\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_as_graph_element_locked\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mallow_tensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mallow_operation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3479\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36m_as_graph_element_locked\u001b[0;34m(self, obj, allow_tensor, allow_operation)\u001b[0m\n\u001b[1;32m   3556\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgraph\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3557\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Tensor %s is not an element of this graph.\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3558\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Tensor Tensor(\"embedding_2/embeddings:0\", shape=(499368, 300), dtype=float32_ref) is not an element of this graph.",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-36-0ebd0b1770c6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0membedding_matrix\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_embedding_matrix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mword_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0membedding_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Building model...'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0membedding_matrix\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mword_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0my_predicted\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_fit_predict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_vec_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_vec_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_y_cat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Test Accuracy:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maccuracy_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_predicted\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-35-c1fee792eeb2>\u001b[0m in \u001b[0;36mget_model\u001b[0;34m(embedding_matrix, word_index, print_sum)\u001b[0m\n\u001b[1;32m      7\u001b[0m                       \u001b[0mweights\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0membedding_matrix\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m                       \u001b[0minput_length\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mMAX_TEXT_LENGTH\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m                       trainable=False)(inp)\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0;31m#model = Dropout(0.2)(model)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs, **kwargs)\u001b[0m\n\u001b[1;32m    434\u001b[0m                 \u001b[0;31m# Load weights that were specified at layer instantiation.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    435\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_initial_weights\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 436\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_weights\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_initial_weights\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    437\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    438\u001b[0m             \u001b[0;31m# Raise exceptions in case the input is not compatible\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/keras/engine/base_layer.py\u001b[0m in \u001b[0;36mset_weights\u001b[0;34m(self, weights)\u001b[0m\n\u001b[1;32m   1049\u001b[0m             \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1050\u001b[0m         \u001b[0mweight_value_tuples\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1051\u001b[0;31m         \u001b[0mparam_values\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mK\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch_get_value\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1052\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mpv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mw\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparam_values\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweights\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1053\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mpv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mw\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36mbatch_get_value\u001b[0;34m(ops)\u001b[0m\n\u001b[1;32m   2418\u001b[0m     \"\"\"\n\u001b[1;32m   2419\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2420\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mget_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mops\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2421\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2422\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    903\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    904\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 905\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    906\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    907\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1123\u001b[0m     \u001b[0;31m# Create a fetch handler to take care of the structure of fetches.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1124\u001b[0m     fetch_handler = _FetchHandler(\n\u001b[0;32m-> 1125\u001b[0;31m         self._graph, fetches, feed_dict_tensor, feed_handles=feed_handles)\n\u001b[0m\u001b[1;32m   1126\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1127\u001b[0m     \u001b[0;31m# Run request and get response.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, graph, fetches, feeds, feed_handles)\u001b[0m\n\u001b[1;32m    425\u001b[0m     \"\"\"\n\u001b[1;32m    426\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mgraph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_default\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 427\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fetch_mapper\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_FetchMapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfor_fetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    428\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fetches\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    429\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_targets\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mfor_fetch\u001b[0;34m(fetch)\u001b[0m\n\u001b[1;32m    243\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    244\u001b[0m       \u001b[0;31m# NOTE(touts): This is also the code path for namedtuples.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 245\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0m_ListFetchMapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    246\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    247\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0m_DictFetchMapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, fetches)\u001b[0m\n\u001b[1;32m    350\u001b[0m     \"\"\"\n\u001b[1;32m    351\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fetch_type\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 352\u001b[0;31m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_mappers\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0m_FetchMapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfor_fetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mfetch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    353\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_unique_fetches\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_value_indices\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_uniquify_fetches\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_mappers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    354\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    350\u001b[0m     \"\"\"\n\u001b[1;32m    351\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fetch_type\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 352\u001b[0;31m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_mappers\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0m_FetchMapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfor_fetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mfetch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    353\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_unique_fetches\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_value_indices\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_uniquify_fetches\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_mappers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    354\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mfor_fetch\u001b[0;34m(fetch)\u001b[0m\n\u001b[1;32m    251\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    252\u001b[0m           \u001b[0mfetches\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcontraction_fn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfetch_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 253\u001b[0;31m           \u001b[0;32mreturn\u001b[0m \u001b[0m_ElementFetchMapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfetches\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcontraction_fn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    254\u001b[0m     \u001b[0;31m# Did not find anything.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    255\u001b[0m     raise TypeError('Fetch argument %r has invalid type %r' % (fetch,\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, fetches, contraction_fn)\u001b[0m\n\u001b[1;32m    287\u001b[0m       \u001b[0;32mexcept\u001b[0m \u001b[0mValueError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    288\u001b[0m         raise ValueError('Fetch argument %r cannot be interpreted as a '\n\u001b[0;32m--> 289\u001b[0;31m                          'Tensor. (%s)' % (fetch, str(e)))\n\u001b[0m\u001b[1;32m    290\u001b[0m       \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    291\u001b[0m         raise ValueError('Fetch argument %r cannot be interpreted as a '\n",
      "\u001b[0;31mValueError\u001b[0m: Fetch argument <tf.Variable 'embedding_2/embeddings:0' shape=(499368, 300) dtype=float32_ref> cannot be interpreted as a Tensor. (Tensor Tensor(\"embedding_2/embeddings:0\", shape=(499368, 300), dtype=float32_ref) is not an element of this graph.)"
     ]
    }
   ],
   "source": [
    "vectors_file_path = '/home/chenxin/WordEmbedding/pre_trained_vectors/raw_300/ft_pure_cbow_300.vec'\n",
    "embedding_index = get_embedding_index(vectors_file_path)\n",
    "embedding_matrix = get_embedding_matrix(word_index, embedding_index)\n",
    "print('Building model...')\n",
    "model = get_model(embedding_matrix, word_index)\n",
    "y_predicted = train_fit_predict(model, x_vec_train, x_vec_test, train_y_cat).argmax(1)\n",
    "print(\"Test Accuracy:\", accuracy_score(y_test, y_predicted))\n",
    "plot_conf_mat(y_test, y_predicted)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous allons évaluer la performance de chaque méthode."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 182711 word vectors.\n",
      "Building embedding matrix...\n",
      "Embedding matrix built.\n",
      "Building model...\n",
      "WARNING:tensorflow:From /home/chenxin/anaconda3/lib/python3.6/site-packages/tensorflow/python/util/deprecation.py:497: calling conv1d (from tensorflow.python.ops.nn_ops) with data_format=NHWC is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "`NHWC` for data_format is deprecated, use `NWC` instead\n",
      "Epoch 1/2\n",
      "192022/192022 [==============================] - 26s 136us/step - loss: 0.2891 - acc: 0.9149\n",
      "Epoch 2/2\n",
      "192022/192022 [==============================] - 25s 131us/step - loss: 0.1714 - acc: 0.9492\n",
      "Test Accuracy: 0.9468972628421447\n",
      "Found 182712 word vectors.\n",
      "Building embedding matrix...\n",
      "Embedding matrix built.\n",
      "Building model...\n",
      "Epoch 1/2\n",
      "192022/192022 [==============================] - 26s 135us/step - loss: 0.4242 - acc: 0.8829\n",
      "Epoch 2/2\n",
      "192022/192022 [==============================] - 25s 132us/step - loss: 0.2367 - acc: 0.9306\n",
      "Test Accuracy: 0.9368672665916761\n",
      "\n",
      "========================================================\n",
      "Test Accuracy of raw_300: 0.936867\n"
     ]
    }
   ],
   "source": [
    "# methods = ['pre_trained_vectors/fasttext_skip.vec',\n",
    "#            'pre_trained_vectors/fasttext_cbow.vec',\n",
    "#            'pre_trained_vectors/word2vec_skip.txt',\n",
    "#            'pre_trained_vectors/word2vec_cbow.txt',\n",
    "#            'pre_trained_vectors/glove.txt']\n",
    "methods = ['pre_trained_vectors/raw_300/ft_pure_skipgram_300.vec',\n",
    "           'pre_trained_vectors/raw_300/ft_pure_cbow_300.vec']\n",
    "accuracies = {}\n",
    "for vector_file in methods:\n",
    "    acc = evaluation(vector_file, print_sum=False, plot_mat=False)\n",
    "    method = vector_file.split('/')[1].split('.')[0]\n",
    "    accuracies[method] = acc\n",
    "print()\n",
    "print('========================================================')\n",
    "for meth, acc in accuracies.items():\n",
    "    print('Test Accuracy of %s: %f' % (meth, acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Les résultats nous ont montrés que la méthode SkipGram a eu une meilleur performance, avec n'import quelle méthode. Au contraire, CBOW n'est pas assez performant. GloVe est presque pareil que CBOWs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2000\n",
      "62\n",
      "109989\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import os\n",
    "import sys\n",
    "import json\n",
    "import gc\n",
    "\n",
    "sys.path.append(\"..\")\n",
    "    \n",
    "from bilm_tf.bilm import TokenBatcher, BidirectionalLanguageModel, \\\n",
    "weight_layers, dump_token_embeddings\n",
    "\n",
    "\n",
    "raw_context = []\n",
    "with open(\"datasets/news_less_category.txt\", \"r\") as f:\n",
    "    for line in f:\n",
    "        temp = line.split('__label__')\n",
    "        raw_context.append(temp[0])\n",
    "        \n",
    "# We only use the part with MAX_TEXT_LENGTH in each sentence(line)\n",
    "tokenized_context = [sentence.split()[:MAX_TEXT_LENGTH] for sentence in raw_context]\n",
    "#tokenized_context = [sentence.split() for sentence in raw_context]\n",
    "max_length = len(tokenized_context[0])\n",
    "max_line = 0\n",
    "lens = []\n",
    "for i in range(len(tokenized_context)):\n",
    "    length = len(tokenized_context[i])\n",
    "    lens.append(length)\n",
    "    if length > max_length:\n",
    "        max_length = length\n",
    "        max_line = i\n",
    "print(max_length)\n",
    "print(max_line)\n",
    "print(len(tokenized_context))\n",
    "# del(lens)\n",
    "# del(raw_context)\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "109989\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1152x648 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(16,9))\n",
    "plt.subplot(121)\n",
    "plt.hist(lens, bins=100, range=(0, 10000))\n",
    "plt.yscale('log')\n",
    "plt.subplot(122)\n",
    "plt.hist(lens, bins=100, range=(0, 10000), cumulative=True)\n",
    "plt.yscale('log')\n",
    "print(len(lens))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dump_vectors(elmo_embedding, prefix, shard_num, dump_batch, nb_batch):\n",
    "    elmo_vectors = np.zeros((dump_batch * nb_batch, MAX_TEXT_LENGTH, elmo_embedding[0].shape[2]))\n",
    "    print(elmo_vectors.shape)\n",
    "    for i in range(elmo_vectors.shape[0]):\n",
    "        elmo_vectors[i, :elmo_embedding[i//dump_batch].shape[1], :] = elmo_embedding[i//dump_batch][i%dump_batch, :, :]\n",
    "\n",
    "    #prefix = 'pre_trained_vectors/elmo_600/elmo_vector_'\n",
    "    outfile = prefix + str(shard_num) + \".hdf5\"\n",
    "    with h5py.File(outfile, 'w') as fout:\n",
    "        ds = fout.create_dataset(\n",
    "            'elmo_vectors', elmo_vectors.shape, dtype='float32', data=elmo_vectors)\n",
    "    del(elmo_vectors)\n",
    "    gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define a DataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataGenerator(Sequence):\n",
    "    \"\"\"\n",
    "    Generates data for Keras\n",
    "    \"\"\"\n",
    "    def __init__(self, x, y, n_classes=11, batch_size=64, shuffle=True):\n",
    "        \"\"\"\n",
    "        Initialization\n",
    "        \"\"\"\n",
    "        self.batch_size = batch_size\n",
    "        self.x = x\n",
    "        self.y = y\n",
    "        self.n_classes = n_classes\n",
    "        self.shuffle = shuffle\n",
    "        self.on_epoch_end()\n",
    "        \n",
    "    def __len__(self):\n",
    "        \"\"\"\n",
    "        Denotes the number of batches per epoch\n",
    "        \"\"\"\n",
    "        return int(np.floor(len(self.x) / self.batch_size))\n",
    "\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        \"\"\"\n",
    "        Generate one batch of data\n",
    "        \"\"\"\n",
    "        # Generate indexes of the batch\n",
    "        indexes = self.indexes[index * self.batch_size:(index + 1) * self.batch_size]\n",
    "\n",
    "        # Generate data\n",
    "        X, y = self.__data_generation(indexes)\n",
    "\n",
    "        return X, y\n",
    "    \n",
    "    \n",
    "    def on_epoch_end(self):\n",
    "        \"\"\"\n",
    "        Updates indexes after each epoch\n",
    "        \"\"\"\n",
    "        self.indexes = np.arange(len(self.y))\n",
    "        if self.shuffle == True:\n",
    "            np.random.shuffle(self.indexes)\n",
    "            \n",
    "            \n",
    "    def __data_generation(self, indexes):\n",
    "        \"\"\"\n",
    "        Generates data containing batch_size samples, X : (n_samples, *dim)\n",
    "        \"\"\"\n",
    "        y = self.y[indexes]\n",
    "        with tf.Session(config=config) as sess:\n",
    "        # It is necessary to initialize variables once before running inference.\n",
    "            sess.run(tf.global_variables_initializer())\n",
    "\n",
    "            # Create batches of data.\n",
    "            elmo_embedding = []\n",
    "            count = 0\n",
    "            tic = time.time()\n",
    "            dump_batch = 64\n",
    "            print(\"Start computing...\")\n",
    "            \n",
    "            context_ids = batcher.batch_sentences(tokenized_context[indexes])\n",
    "            #print(context_ids.shape)\n",
    "\n",
    "            # Compute ELMo representations (here for the input only, for simplicity).\n",
    "            elmo_context_input_ = sess.run(\n",
    "                [elmo_context_input['weighted_op']],\n",
    "                feed_dict={context_token_ids: context_ids}\n",
    "            )\n",
    "            \n",
    "        return elmo_context_input_, y\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "USING SKIP CONNECTIONS\n",
      "Dataset splited.\n",
      "Converting data to trainable form...\n",
      "Number of training examples: 98990\n",
      "Number of test examples: 10999\n"
     ]
    }
   ],
   "source": [
    "vocab_file = '/home/chenxin/WordEmbedding/pre_trained_vectors/raw_300/ft_5_vocab.txt'\n",
    "options_file = '/home/chenxin/ELMo/pure_checkpoint/options.json'\n",
    "weight_file = '/home/chenxin/ELMo/pure_checkpoint/weights.hdf5'\n",
    "token_embedding_file = '/home/chenxin/WordEmbedding/pre_trained_vectors/raw_300/vocab_embedding.hdf5'\n",
    "prefix = 'pre_trained_vectors/elmo_600/elmo_vector_'\n",
    "with open(options_file, 'r') as fin:\n",
    "    options = json.load(fin)\n",
    "\n",
    "tf.reset_default_graph()\n",
    "## Now we can do inference.\n",
    "# Create a TokenBatcher to map text to token ids.\n",
    "batcher = TokenBatcher(vocab_file)\n",
    "\n",
    "# Input placeholders to the biLM.\n",
    "context_token_ids = tf.placeholder('int32', shape=(None, None))\n",
    "\n",
    "# Build the biLM graph.\n",
    "bilm = BidirectionalLanguageModel(\n",
    "    options_file,\n",
    "    weight_file,\n",
    "    use_character_inputs=False,\n",
    "    embedding_weight_file=token_embedding_file\n",
    ")\n",
    "\n",
    "# Get ops to compute the LM embeddings.\n",
    "context_embeddings_op = bilm(context_token_ids)\n",
    "config = tf.ConfigProto(allow_soft_placement=True)\n",
    "\n",
    "#with tf.variable_scope('', reuse=True):\n",
    "elmo_context_input = weight_layers('input', context_embeddings_op, l2_coef=0.0)\n",
    "\n",
    "#with tf.variable_scope('', reuse=True):\n",
    "elmo_context_output = weight_layers('output', context_embeddings_op, l2_coef=0.0)   \n",
    "\n",
    "x_train, x_test, y_train, y_test = split_datasets([\"datasets/news_less_category.txt\"], 0.1)\n",
    "x_vec_train, x_vec_test, y_train, y_test, train_y_cat, word_index = class_str_2_ind(x_train=x_train, x_test=x_test,\\\n",
    "                                                                                    y_train=y_train, y_test=y_test)\n",
    "# Parameters\n",
    "params = {'batch_size': 64,\n",
    "          'n_classes': 11,\n",
    "          'shuffle': True}\n",
    "\n",
    "\n",
    "# Generators\n",
    "training_generator = DataGenerator(x_vec_train, y_train, **params)\n",
    "test_generator = DataGenerator(x_vec_test, y_test, **params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 2000, 600)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_1 (Conv1D)            (None, 2000, 32)          96032     \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 2000, 32)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_1 (MaxPooling1 (None, 1000, 32)          0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 32000)             0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 512)               16384512  \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 11)                5643      \n",
      "=================================================================\n",
      "Total params: 16,486,187\n",
      "Trainable params: 16,486,187\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-33-b062c1d1e681>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msummary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_generator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtraining_generator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_generator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_generator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Test Accuracy:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maccuracy_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_predicted\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/keras/legacy/interfaces.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     89\u001b[0m                 warnings.warn('Update your `' + object_name + '` call to the ' +\n\u001b[1;32m     90\u001b[0m                               'Keras 2 API: ' + signature, stacklevel=2)\n\u001b[0;32m---> 91\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     92\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m   1416\u001b[0m             \u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1417\u001b[0m             \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1418\u001b[0;31m             initial_epoch=initial_epoch)\n\u001b[0m\u001b[1;32m   1419\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1420\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0minterfaces\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlegacy_generator_methods_support\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/keras/engine/training_generator.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(model, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m    179\u001b[0m             \u001b[0mbatch_index\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    180\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0msteps_done\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 181\u001b[0;31m                 \u001b[0mgenerator_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_generator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    182\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    183\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgenerator_output\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'__len__'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/keras/utils/data_utils.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    593\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    594\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_running\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 595\u001b[0;31m                 \u001b[0minputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mqueue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mblock\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    596\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mqueue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtask_done\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    597\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0minputs\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/multiprocessing/pool.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    636\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    637\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 638\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    639\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mready\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    640\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mTimeoutError\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/multiprocessing/pool.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    633\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    634\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 635\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_event\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    636\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    637\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    549\u001b[0m             \u001b[0msignaled\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_flag\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    550\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0msignaled\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 551\u001b[0;31m                 \u001b[0msignaled\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cond\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    552\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0msignaled\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    553\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    293\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m    \u001b[0;31m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    294\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 295\u001b[0;31m                 \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    296\u001b[0m                 \u001b[0mgotit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    297\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "inp = Input(shape=(MAX_TEXT_LENGTH, 600))\n",
    "\n",
    "#model = Dropout(0.2)(model)\n",
    "model = Conv1D(filters=32, kernel_size=5, padding='same', activation='relu')(inp)\n",
    "model = Dropout(0.5)(model)\n",
    "model = MaxPooling1D(pool_size=2)(model)\n",
    "#model = Conv1D(filters=32, kernel_size=3, padding='same', activation='relu')(model)\n",
    "#model = Dropout(0.5)(model)\n",
    "#model = MaxPooling1D(pool_size=2)(model)\n",
    "model = Flatten()(model)\n",
    "model = Dense(512, activation='relu')(model)\n",
    "model = Dropout(0.5)(model)\n",
    "model = Dense(11, activation=\"softmax\")(model)\n",
    "model = Model(inputs=inp, outputs=model)\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "model.summary()\n",
    "    \n",
    "model.fit_generator(training_generator, use_multiprocessing=True)\n",
    "y_pred = model.predict_generator(test_generator).argmax(1)\n",
    "print(\"Test Accuracy:\", accuracy_score(y_test, y_predicted))\n",
    "plot_conf_mat(y_test, y_predicted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "USING SKIP CONNECTIONS\n",
      "WARNING:tensorflow:From ../bilm_tf/bilm/elmo.py:89: calling squeeze (from tensorflow.python.ops.array_ops) with squeeze_dims is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use the `axis` argument instead\n",
      "Start computing...\n",
      "(1920, 2000, 600)\n",
      "Batch number: 30\n",
      "Total time: 128.10360074043274s\n",
      "(1920, 2000, 600)\n",
      "Batch number: 60\n",
      "Total time: 266.5128540992737s\n",
      "(1920, 2000, 600)\n",
      "Batch number: 90\n",
      "Total time: 403.8405010700226s\n",
      "(1920, 2000, 600)\n",
      "Batch number: 120\n",
      "Total time: 542.5585525035858s\n",
      "(1920, 2000, 600)\n",
      "Batch number: 150\n",
      "Total time: 680.9262328147888s\n",
      "(1920, 2000, 600)\n",
      "Batch number: 180\n",
      "Total time: 808.8398036956787s\n",
      "(1920, 2000, 600)\n",
      "Batch number: 210\n",
      "Total time: 954.7504844665527s\n",
      "(1920, 2000, 600)\n",
      "Batch number: 240\n",
      "Total time: 1082.4198455810547s\n",
      "(1920, 2000, 600)\n",
      "Batch number: 270\n",
      "Total time: 1213.3511128425598s\n",
      "(1920, 2000, 600)\n",
      "Batch number: 300\n",
      "Total time: 1359.203447818756s\n",
      "(1920, 2000, 600)\n",
      "Batch number: 330\n",
      "Total time: 1493.5101065635681s\n",
      "(1920, 2000, 600)\n",
      "Batch number: 360\n",
      "Total time: 1631.0171480178833s\n",
      "(1920, 2000, 600)\n",
      "Batch number: 390\n",
      "Total time: 1765.742110490799s\n",
      "(1920, 2000, 600)\n",
      "Batch number: 420\n",
      "Total time: 1913.1447882652283s\n",
      "(1920, 2000, 600)\n",
      "Batch number: 450\n",
      "Total time: 2046.8428766727448s\n",
      "(1920, 2000, 600)\n",
      "Batch number: 480\n",
      "Total time: 2193.0354011058807s\n",
      "(1920, 2000, 600)\n",
      "Batch number: 510\n",
      "Total time: 2328.8442182540894s\n",
      "(1920, 2000, 600)\n",
      "Batch number: 540\n",
      "Total time: 2474.0715930461884s\n",
      "(1920, 2000, 600)\n",
      "Batch number: 570\n",
      "Total time: 2620.2150871753693s\n",
      "(1920, 2000, 600)\n",
      "Batch number: 600\n",
      "Total time: 2766.309875011444s\n",
      "(1920, 2000, 600)\n",
      "Batch number: 630\n",
      "Total time: 2890.5430076122284s\n",
      "(1920, 2000, 600)\n",
      "Batch number: 660\n",
      "Total time: 2992.600321531296s\n",
      "(1920, 2000, 600)\n",
      "Batch number: 690\n",
      "Total time: 3093.5793023109436s\n",
      "(1920, 2000, 600)\n",
      "Batch number: 720\n",
      "Total time: 3201.1702468395233s\n",
      "(1920, 2000, 600)\n",
      "Batch number: 750\n",
      "Total time: 3317.263195514679s\n",
      "(1920, 2000, 600)\n",
      "Batch number: 780\n",
      "Total time: 3422.0636773109436s\n",
      "(1920, 2000, 600)\n",
      "Batch number: 810\n",
      "Total time: 3559.477064847946s\n",
      "(1920, 2000, 600)\n",
      "Batch number: 840\n",
      "Total time: 3684.095625400543s\n",
      "(1920, 2000, 600)\n",
      "Batch number: 870\n",
      "Total time: 3798.3041849136353s\n",
      "(1920, 2000, 600)\n",
      "Batch number: 900\n",
      "Total time: 3920.793709754944s\n",
      "(1920, 2000, 600)\n",
      "Batch number: 930\n",
      "Total time: 4042.0809319019318s\n",
      "(1920, 2000, 600)\n",
      "Batch number: 960\n",
      "Total time: 4176.059525966644s\n",
      "(1920, 2000, 600)\n",
      "Batch number: 990\n",
      "Total time: 4323.918107748032s\n",
      "(1920, 2000, 600)\n",
      "Batch number: 1020\n",
      "Total time: 4455.093926906586s\n",
      "(1920, 2000, 600)\n",
      "Batch number: 1050\n",
      "Total time: 4593.592587471008s\n",
      "(1920, 2000, 600)\n",
      "Batch number: 1080\n",
      "Total time: 4721.214941978455s\n",
      "(1920, 2000, 600)\n",
      "Batch number: 1110\n",
      "Total time: 4849.080104827881s\n",
      "(1920, 2000, 600)\n",
      "Batch number: 1140\n",
      "Total time: 4982.370371341705s\n",
      "(1920, 2000, 600)\n",
      "Batch number: 1170\n",
      "Total time: 5114.234558582306s\n",
      "(1920, 2000, 600)\n",
      "Batch number: 1200\n",
      "Total time: 5244.188905954361s\n",
      "(1920, 2000, 600)\n",
      "Batch number: 1230\n",
      "Total time: 5374.69296836853s\n",
      "(1920, 2000, 600)\n",
      "Batch number: 1260\n",
      "Total time: 5506.736935853958s\n",
      "(1920, 2000, 600)\n",
      "Batch number: 1290\n",
      "Total time: 5634.770679473877s\n",
      "(1920, 2000, 600)\n",
      "Batch number: 1320\n",
      "Total time: 5764.641933441162s\n",
      "(1920, 2000, 600)\n",
      "Batch number: 1350\n",
      "Total time: 5890.902672529221s\n",
      "(1920, 2000, 600)\n",
      "Batch number: 1380\n",
      "Total time: 6021.106119394302s\n",
      "(1920, 2000, 600)\n",
      "Batch number: 1410\n",
      "Total time: 6149.02947807312s\n",
      "(1920, 2000, 600)\n",
      "Batch number: 1440\n",
      "Total time: 6274.476670503616s\n",
      "(1920, 2000, 600)\n",
      "Batch number: 1470\n",
      "Total time: 6400.644941329956s\n",
      "(1920, 2000, 600)\n",
      "Batch number: 1500\n",
      "Total time: 6528.604142904282s\n",
      "(1920, 2000, 600)\n",
      "Batch number: 1530\n",
      "Total time: 6652.9251210689545s\n",
      "(1920, 2000, 600)\n",
      "Batch number: 1560\n",
      "Total time: 6775.6640021800995s\n",
      "(1920, 2000, 600)\n",
      "Batch number: 1590\n",
      "Total time: 6905.136388540268s\n",
      "(1920, 2000, 600)\n",
      "Batch number: 1620\n",
      "Total time: 7033.437812566757s\n",
      "(1920, 2000, 600)\n",
      "Batch number: 1650\n",
      "Total time: 7161.039949178696s\n",
      "(1920, 2000, 600)\n",
      "Batch number: 1680\n",
      "Total time: 7287.2544894218445s\n",
      "(1920, 2000, 600)\n",
      "Batch number: 1710\n",
      "Total time: 7414.996106863022s\n"
     ]
    }
   ],
   "source": [
    "vocab_file = '/home/chenxin/WordEmbedding/pre_trained_vectors/raw_300/ft_5_vocab.txt'\n",
    "options_file = '/home/chenxin/ELMo/pure_checkpoint/options.json'\n",
    "weight_file = '/home/chenxin/ELMo/pure_checkpoint/weights.hdf5'\n",
    "token_embedding_file = '/home/chenxin/WordEmbedding/pre_trained_vectors/raw_300/vocab_embedding.hdf5'\n",
    "prefix = 'pre_trained_vectors/elmo_600/elmo_vector_'\n",
    "with open(options_file, 'r') as fin:\n",
    "    options = json.load(fin)\n",
    "\n",
    "tf.reset_default_graph()\n",
    "## Now we can do inference.\n",
    "# Create a TokenBatcher to map text to token ids.\n",
    "batcher = TokenBatcher(vocab_file)\n",
    "\n",
    "# Input placeholders to the biLM.\n",
    "context_token_ids = tf.placeholder('int32', shape=(None, None))\n",
    "\n",
    "# Build the biLM graph.\n",
    "bilm = BidirectionalLanguageModel(\n",
    "    options_file,\n",
    "    weight_file,\n",
    "    use_character_inputs=False,\n",
    "    embedding_weight_file=token_embedding_file\n",
    ")\n",
    "\n",
    "# Get ops to compute the LM embeddings.\n",
    "context_embeddings_op = bilm(context_token_ids)\n",
    "config = tf.ConfigProto(allow_soft_placement=True)\n",
    "\n",
    "#with tf.variable_scope('', reuse=True):\n",
    "elmo_context_input = weight_layers('input', context_embeddings_op, l2_coef=0.0)\n",
    "\n",
    "#with tf.variable_scope('', reuse=True):\n",
    "elmo_context_output = weight_layers('output', context_embeddings_op, l2_coef=0.0)\n",
    "\n",
    "\n",
    "with tf.Session(config=config) as sess:\n",
    "    # It is necessary to initialize variables once before running inference.\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "\n",
    "    # Create batches of data.\n",
    "    elmo_embedding = []\n",
    "    count = 0\n",
    "    tic = time.time()\n",
    "    dump_batch = 64\n",
    "    print(\"Start computing...\")\n",
    "    for i in range(0, len(tokenized_context), dump_batch):\n",
    "        context_ids = batcher.batch_sentences(tokenized_context[i:i+dump_batch])\n",
    "        #print(context_ids.shape)\n",
    "\n",
    "        # Compute ELMo representations (here for the input only, for simplicity).\n",
    "        elmo_context_input_ = sess.run(\n",
    "            [elmo_context_input['weighted_op']],\n",
    "            feed_dict={context_token_ids: context_ids}\n",
    "        )\n",
    "        elmo_embedding += elmo_context_input_\n",
    "        count += 1\n",
    "            \n",
    "        if count % 30 == 0:\n",
    "            dump_vectors(elmo_embedding, prefix, count // 30, dump_batch, 30)\n",
    "            toc = time.time()\n",
    "            print(\"Batch number: \" + str(count))\n",
    "            print(\"Total time: \" + str(toc - tic) + \"s\")\n",
    "            del(elmo_embedding)\n",
    "            gc.collect()\n",
    "            elmo_embedding = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.02679283  0.14638782 -0.20909283 ... -0.317909   -0.36457983\n",
      "  -1.0772837 ]\n",
      " [ 0.11242183  0.17796426 -0.08126539 ...  0.01473063 -0.2738471\n",
      "  -0.97115237]\n",
      " [ 0.0379664  -0.11325606 -0.05286891 ... -0.3455569  -0.24749027\n",
      "  -1.0140477 ]\n",
      " ...\n",
      " [ 0.          0.          0.         ...  0.          0.\n",
      "   0.        ]\n",
      " [ 0.          0.          0.         ...  0.          0.\n",
      "   0.        ]\n",
      " [ 0.          0.          0.         ...  0.          0.\n",
      "   0.        ]]\n"
     ]
    }
   ],
   "source": [
    "f = h5py.File('/home/jitao/WordEmbedding/pre_trained_vectors/elmo_600/elmo_vector_1.hdf5', 'r')\n",
    "vector1 = f['elmo_vectors'][0]\n",
    "print(vector1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
