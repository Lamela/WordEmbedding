{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'abs'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-3aab7b816843>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m#from nn_utils import TrainingHistory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mDense\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mEmbedding\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mInput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mGRU\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDropout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mMaxPooling1D\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mConv1D\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mFlatten\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodels\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mModel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/keras/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0m__future__\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mabsolute_import\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mutils\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mactivations\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mapplications\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/keras/utils/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdata_utils\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mio_utils\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mconv_utils\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;31m# Globally-importable utils.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/keras/utils/conv_utils.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmoves\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mbackend\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mK\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/keras/backend/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     87\u001b[0m \u001b[0;32melif\u001b[0m \u001b[0m_BACKEND\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'tensorflow'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     88\u001b[0m     \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstderr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Using TensorFlow backend.\\n'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 89\u001b[0;31m     \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mtensorflow_backend\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     90\u001b[0m \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m     \u001b[0;31m# Try and load external backend.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0m__future__\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mprint_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mtensorflow\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mframework\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mops\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtf_ops\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraining\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmoving_averages\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/tensorflow/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;31m# pylint: disable=g-bad-import-order\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpywrap_tensorflow\u001b[0m  \u001b[0;31m# pylint: disable=unused-import\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/tensorflow/python/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     79\u001b[0m \u001b[0;31m# Bring in subpackages.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     80\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 81\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     82\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeature_column\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mfeature_column_lib\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mfeature_column\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     83\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mlayers\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/tensorflow/python/keras/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0m__future__\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mprint_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mactivations\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mapplications\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mbackend\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/tensorflow/python/keras/activations/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;31m# Activation functions.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_impl\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mactivations\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0melu\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_impl\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mactivations\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mhard_sigmoid\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_impl\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mactivations\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mlinear\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/tensorflow/python/keras/_impl/keras/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0m__future__\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mprint_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_impl\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mactivations\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_impl\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mapplications\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_impl\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mbackend\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/tensorflow/python/keras/_impl/keras/activations.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0msix\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_impl\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mbackend\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mK\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_impl\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgeneric_utils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdeserialize_keras_object\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbase\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mLayer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/tensorflow/python/keras/_impl/keras/backend.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mframework\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0msparse_tensor\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mframework\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtensor_util\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 38\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mbase\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtf_base_layers\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     39\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mops\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0marray_ops\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mops\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mclip_ops\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/tensorflow/python/layers/base.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mframework\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdtypes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mframework\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mbase_layer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mops\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mvariable_scope\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mvs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mops\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mvariables\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtf_variables\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/tensorflow/python/keras/engine/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;31m# TODO(fchollet): Remove hourglass imports once external code is done importing\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;31m# non-public APIs.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbase_layer\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mInputSpec\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbase_layer\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mLayer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minput_layer\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mInput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/tensorflow/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mframework\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtensor_shape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mframework\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtensor_util\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 33\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mbackend\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     34\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mconstraints\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0minitializers\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/tensorflow/python/keras/backend/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;31m# pylint: disable=redefined-builtin\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_impl\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackend\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mabs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_impl\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackend\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mall\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_impl\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackend\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0many\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mImportError\u001b[0m: cannot import name 'abs'"
     ]
    }
   ],
   "source": [
    "import ast\n",
    "import os\n",
    "#from nn_utils import TrainingHistory\n",
    "from keras.layers import Dense, Embedding, Input\n",
    "from keras.layers import GRU, Dropout, MaxPooling1D, Conv1D, Flatten\n",
    "from keras.models import Model\n",
    "import numpy as np\n",
    "import itertools\n",
    "from keras.utils import np_utils\n",
    "from sklearn.metrics import (classification_report, \n",
    "                             precision_recall_fscore_support, \n",
    "                             accuracy_score)\n",
    "import numpy as np\n",
    "from keras.preprocessing import text, sequence\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Model parameters\n",
    "MAX_FEATURES = 183312# YOUR CODE HERE\n",
    "MAX_TEXT_LENGTH = 1024# YOUR CODE HERE\n",
    "EMBED_SIZE  = 100# YOUR CODE HERE\n",
    "BATCH_SIZE = 16\n",
    "EPOCHS = 2\n",
    "VALIDATION_SPLIT = 0.1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous définissons un modèle de classification de texte avec une couche de Conv1D et une couche de Dense. Nous pouvons utiliser les vecteurs de mots pré-appris. Le modèle est basé sur le [TP de M. Kermorvant](https://gitlab.com/kermorvant/nlp-labs)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_train_test(train_raw_text, test_raw_text):\n",
    "    \n",
    "    tokenizer = text.Tokenizer(num_words=MAX_FEATURES)\n",
    "\n",
    "    tokenizer.fit_on_texts(list(train_raw_text))\n",
    "    train_tokenized = tokenizer.texts_to_sequences(train_raw_text)\n",
    "    test_tokenized = tokenizer.texts_to_sequences(test_raw_text)\n",
    "    return sequence.pad_sequences(train_tokenized, maxlen=MAX_TEXT_LENGTH), \\\n",
    "           sequence.pad_sequences(test_tokenized, maxlen=MAX_TEXT_LENGTH)\n",
    "\n",
    "\n",
    "\n",
    "def get_model(embedding_matrix):\n",
    "\n",
    "    inp = Input(shape=(MAX_TEXT_LENGTH,))\n",
    "    #modification here\n",
    "    model = Embedding(len(word_index) + 1,\n",
    "                      EMBED_SIZE,\n",
    "                      weights=[embedding_matrix],\n",
    "                      input_length=MAX_TEXT_LENGTH,\n",
    "                      trainable=False)(inp)\n",
    "    \n",
    "    model = Dropout(0.5)(model)\n",
    "    model = Conv1D(filters=32, kernel_size=2, padding='same', activation='relu')(model)\n",
    "    model = MaxPooling1D(pool_size=2)(model)\n",
    "    model = Flatten()(model)\n",
    "    model = Dense(11, activation=\"softmax\")(model)\n",
    "    model = Model(inputs=inp, outputs=model)\n",
    "    \n",
    "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    model.summary()\n",
    "    return model\n",
    "\n",
    "\n",
    "def train_fit_predict(model, x_train, x_test, y_train):\n",
    "    \n",
    "    model.fit(x_train, y_train,\n",
    "              batch_size=BATCH_SIZE,\n",
    "              epochs=EPOCHS, verbose=1)\n",
    "\n",
    "    return model.predict(x_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous lisons le jeu de données d'apprentissage et de test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = []\n",
    "y_train = []\n",
    "x_test = []\n",
    "y_test = []\n",
    "with open('datasets/news_less_category.txt', 'r') as f:\n",
    "    for line in f:\n",
    "        temp = line.split('__label__')\n",
    "        x_train.append(temp[0])\n",
    "        y_train.append(temp[1])\n",
    "with open('datasets/news_fasttext_test.txt', 'r') as f:\n",
    "    for line in f:\n",
    "        temp = line.split('__label__')\n",
    "        x_test.append(temp[0])\n",
    "        y_test.append(temp[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Si l'on définit les jeux de données d'apprentissage et test comme ça, la taille de jeux de données est super élevée. Dans ce cas-là, le temps de calcul va exploser. Nous décidons de prendre le jeu de données de test, puis faire le découpage afin d'obtenir le jeu de données d'apprentissage utilisé et le jeu de données de test utilisé."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_datasets(data_path, test_size):\n",
    "    x = []\n",
    "    y = []\n",
    "    with open(data_path, 'r') as f:\n",
    "        for line in f:\n",
    "            temp = line.split('__label__')\n",
    "            x.append(temp[0])\n",
    "            y.append(temp[1])\n",
    "            \n",
    "    x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=test_size)\n",
    "    \n",
    "    return x_train, x_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Maintenant nous allons lire les vecteurs de mots pré-appris. Cette partie est basé sur le [tutoriel de Keras](https://blog.keras.io/using-pre-trained-word-embeddings-in-a-keras-model.html) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "183312 100\n",
      "\n",
      "Found 183312 word vectors.\n"
     ]
    }
   ],
   "source": [
    "embeddings_index = {}\n",
    "with open('model_pure_skip.vec', 'r') as f:\n",
    "    first_line = f.readline()\n",
    "    print(first_line)\n",
    "    for line in f:\n",
    "        values = line.split()\n",
    "        word = values[0]\n",
    "        coefs = np.asarray(values[1:], dtype='float32')\n",
    "        embeddings_index[word] = coefs\n",
    "\n",
    "\n",
    "print('Found %s word vectors.' % len(embeddings_index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_embedding_index(vectors_path):\n",
    "    embeddings_index = {}\n",
    "    with open(vectors_path, 'r') as f:\n",
    "        first_line = f.readline()\n",
    "        print(first_line)\n",
    "        for line in f:\n",
    "            values = line.split()\n",
    "            word = values[0]\n",
    "            coefs = np.asarray(values[1:], dtype='float32')\n",
    "            embeddings_index[word] = coefs\n",
    "            \n",
    "    print('Found %s word vectors.' % len(embeddings_index))\n",
    "    \n",
    "    return embeddings_index\n",
    "\n",
    "\n",
    "def get_embedding_matrix(x_train, embedding_index)：\n",
    "    tokenizer = text.Tokenizer(num_words=MAX_FEATURES)\n",
    "    tokenizer.fit_on_texts(x_train)\n",
    "    word_index = tokenizer.word_index\n",
    "    embedding_matrix = np.zeros((len(word_index) + 1, EMBED_SIZE))\n",
    "    for word, i in word_index.items():\n",
    "        embedding_vector = embeddings_index.get(word)\n",
    "        if embedding_vector is not None:\n",
    "            # words not found in embedding index will be all-zeros.\n",
    "            embedding_matrix[i] = embedding_vector\n",
    "            \n",
    "    return embedding_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = text.Tokenizer(num_words=MAX_FEATURES)\n",
    "tokenizer.fit_on_texts(x_train)\n",
    "word_index = tokenizer.word_index\n",
    "embedding_matrix = np.zeros((len(word_index) + 1, EMBED_SIZE))\n",
    "for word, i in word_index.items():\n",
    "    embedding_vector = embeddings_index.get(word)\n",
    "    if embedding_vector is not None:\n",
    "        # words not found in embedding index will be all-zeros.\n",
    "        embedding_matrix[i] = embedding_vector"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous allons d'abord tokenizer les données au format pour le réseau de neurones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['affairs\\n' 'economic\\n' 'edu\\n' 'ent\\n' 'fashion\\n' 'game\\n' 'home\\n'\n",
      " 'house\\n' 'science\\n' 'sports\\n' 'stock\\n']\n",
      "109989 103369\n"
     ]
    }
   ],
   "source": [
    "# Get the list of different classes\n",
    "CLASSES_LIST = np.unique(y_train)\n",
    "n_out = len(CLASSES_LIST)\n",
    "print(CLASSES_LIST)\n",
    "\n",
    "# Convert clas string to index\n",
    "from sklearn import preprocessing\n",
    "le = preprocessing.LabelEncoder()\n",
    "le.fit(CLASSES_LIST)\n",
    "y_train = le.transform(y_train) \n",
    "y_test = le.transform(y_test) \n",
    "train_y_cat = np_utils.to_categorical(y_train, n_out)\n",
    "\n",
    "# get the textual data in the correct format for NN\n",
    "x_vec_train, x_vec_test = get_train_test(x_train, x_test)\n",
    "print(len(x_vec_train), len(x_vec_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n",
    "Nous entraînons le modèle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/xujitao/.local/lib/python3.6/site-packages/tensorflow/python/util/deprecation.py:497: calling conv1d (from tensorflow.python.ops.nn_ops) with data_format=NHWC is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "`NHWC` for data_format is deprecated, use `NWC` instead\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "embedding_1 (Embedding)      (None, 1024, 100)         52613700  \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 1024, 100)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_1 (Conv1D)            (None, 1024, 32)          6432      \n",
      "_________________________________________________________________\n",
      "max_pooling1d_1 (MaxPooling1 (None, 512, 32)           0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 16384)             0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 11)                180235    \n",
      "=================================================================\n",
      "Total params: 52,800,367\n",
      "Trainable params: 186,667\n",
      "Non-trainable params: 52,613,700\n",
      "_________________________________________________________________\n",
      "Epoch 1/2\n",
      "109989/109989 [==============================] - 192s 2ms/step - loss: 0.3572 - acc: 0.8983\n",
      "Epoch 2/2\n",
      "109989/109989 [==============================] - 193s 2ms/step - loss: 0.2349 - acc: 0.9318\n",
      "Test Accuracy: 0.9291760585862299\n",
      "p r f1 92.9 92.92 92.918\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.93      0.89      0.91     10000\n",
      "          1       0.91      0.90      0.91     10000\n",
      "          2       0.95      0.95      0.95     10000\n",
      "          3       0.94      0.95      0.94     10000\n",
      "          4       0.85      0.95      0.90      3369\n",
      "          5       0.96      0.92      0.94     10000\n",
      "          6       0.91      0.95      0.93     10000\n",
      "          7       0.99      0.99      0.99     10000\n",
      "          8       0.88      0.86      0.87     10000\n",
      "          9       0.97      0.98      0.98     10000\n",
      "         10       0.88      0.88      0.88     10000\n",
      "\n",
      "avg / total       0.93      0.93      0.93    103369\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# define the NN topology\n",
    "model = get_model(embedding_matrix)\n",
    "\n",
    "# Define training procedure\n",
    "#history = TrainingHistory(x_vec_test, y_test, CLASSES_LIST)\n",
    "\n",
    "# Train and predict\n",
    "y_predicted = train_fit_predict(model, x_vec_train, x_vec_test, train_y_cat).argmax(1)\n",
    "\n",
    "\n",
    "print(\"Test Accuracy:\", accuracy_score(y_test, y_predicted))\n",
    "\n",
    "p, r, f1, s = precision_recall_fscore_support(y_test, y_predicted, \n",
    "                                              average='micro',\n",
    "                                              labels=[x for x in \n",
    "                                                      np.unique(y_train) \n",
    "                                                      if x not in ['CSDECMOTV']])\n",
    "\n",
    "print('p r f1 %.1f %.2f %.3f' % (np.average(p, weights=s)*100.0, \n",
    "                                 np.average(r, weights=s)*100.0, \n",
    "                                 np.average(f1, weights=s)*100.0))\n",
    "\n",
    "\n",
    "print(classification_report(y_test, y_predicted, labels=[x for x in \n",
    "                                                       np.unique(y_train) \n",
    "                                                       if x not in ['CSDECMOTV']]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n",
    "Nous allons plotter la matrice de confusion, code basé sur [l'exemple de sklearn](http://scikit-learn.org/stable/auto_examples/model_selection/plot_confusion_matrix.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "from plot_util import plot_confusion_matrix\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix, without normalization\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'np' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-24-dd36e8d8a2ec>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfigsize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msubplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m121\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mplot_confusion_matrix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconf_mat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclass_names\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtitle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'Confusion matrix, without normalization'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msubplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m122\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mplot_confusion_matrix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconf_mat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclass_names\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnormalize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtitle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'Normalized confusion matrix'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/WordEmbedding/plot_util.py\u001b[0m in \u001b[0;36mplot_confusion_matrix\u001b[0;34m(cm, classes, normalize, title, cmap)\u001b[0m\n\u001b[1;32m     21\u001b[0m     \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtitle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtitle\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m     \u001b[0;31m#plt.colorbar()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m     \u001b[0mtick_marks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclasses\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m     \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mxticks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtick_marks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclasses\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrotation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m45\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m     \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0myticks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtick_marks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclasses\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'np' is not defined"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAASMAAAEtCAYAAABDKgZdAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMi4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvhp/UCwAAFW1JREFUeJzt3XuQXGWdxvHvM7lAuCwEExECGlYQRSyBHVkEBQpwF5UVtsoLCCzihXVLEBAXEXHBRV21lIJSVzcCgoCAIquIrIByW3Y1Rbi4QoIQIEBuMOEOAknIb/8472BnTDI93X2mfzP9fKqmZrr79Ht+fc7pp99zmX4VEZiZdVtftwswMwOHkZkl4TAysxQcRmaWgsPIzFJwGJlZCuM+jCRNkfRzSU9J+nEb7Rwq6ZpO1tYtkt4u6Q9Z5idppqSQNHG0ahorJC2QtF/5+2RJZ9cwj+9K+nyn2x1xHVmuM5L0QeBTwOuBZ4A7gC9FxM1ttns4cAywe0SsbLvQ5CQFsF1EzO92LWsjaQHw0Yj4Vbk9E3gAmNTpdSTpPGBhRJzSyXZHy9Bl1YH2PlTae1sn2uukFD0jSZ8CzgS+DGwOvBr4d+DADjT/GuCeXgiiZrj3UR8v2zZFRFd/gE2AZ4H3rWOa9ajCanH5ORNYrzy2N7AQOAF4FFgCHFke+wKwHFhR5vER4DTgwoa2ZwIBTCy3PwTcT9U7ewA4tOH+mxuetztwC/BU+b17w2M3AKcD/1PauQaYtpbXNlj/iQ31HwS8C7gHeBw4uWH6XYHfAE+Wab8FTC6P3VRey3Pl9X6gof3PAEuBCwbvK895bZnHLuX2lsAAsHcT6+584ITy94wy708MabdvyPwuAFYBz5caT2xYB0cADwHLgM81uf5XWy/lvgC2BY4q6355mdfP1/I6Avg4cG9Zrt/mT3sNfcApwINl/fwA2GTItvORUvdNDfcdCTwMPFHafgvwf6X9bzXM+7XAdcBj5XVfBGza8PgCYL/y92mUbbes92cbflYCp5XHTgLuo9r25gJ/X+5/A/AC8FJ5zpPl/vOALzbM82PA/LL+rgC2bGZZtZ0FCcJo/7IgJ65jmn8Ffgu8EpgO/C9wesObeWWZZhLVm/iPwNShK3Attwc3nonAhsDTwPblsS2ANw7d6IHNykZ2eHneIeX2KxrC6D7gdcCUcvsr6wijlcC/lPo/RhUGPwQ2Bt5I9cbdpkz/V8BuZb4zgXnAcUPfiGto/6tUb+opNIRDw8Y3F9gAuBr4epPr7sOUNzjwwfKaL2147GcNNTTObwHlDTZkHXyv1Pdm4EXgDU2s/5fXy5qWAUPeaOsIoyuBTal65QPA/g2vYz7wl8BGwOXABUPq/gHVtjOl4b7vAusDf0MVAD8t9c+gCrW9ShvbAu8o62Y6VaCdOVwYDal/p1LzzuX2+6g+VPqoPpCeA7ZYx/J6eRkB+1CF4i6lpm8CNzWzrNr9ybCb9gpgWax7N+pQ4F8j4tGIGKDq8Rze8PiK8viKiLiKKvW3b7GeVcCOkqZExJKIuGsN07wbuDciLoiIlRFxMXA38HcN03w/Iu6JiOeBH1FtMGuzgur42ArgEmAacFZEPFPmP5fqDUpE3BoRvy3zXQD8B7BXE6/p1Ih4sdSzmoj4HtUbbjZVAH9umPYG3Qi8TVIfsCfwNWCP8the5fGR+EJEPB8RvwN+R3nNDL/+O+ErEfFkRDwEXM+f1tehwBkRcX9EPAt8Fjh4yC7ZaRHx3JBle3pEvBAR11CFwcWl/kXAfwM7A0TE/Ii4tqybAeAMhl+fL5M0nSrojomI20ubP46IxRGxKiIuperF7Npkk4cC50bEbRHxYnm9by3H9QatbVm1JUMYPQZMG2Z/e0uqbvKgB8t9L7cxJMz+SPUpNiIR8RzVJ8nHgSWSfiHp9U3UM1jTjIbbS0dQz2MR8VL5e3CDfqTh8ecHny/pdZKulLRU0tNUx9mmraNtgIGIeGGYab4H7Ah8s2yEw4qI+6jeaDsBb6f6xFwsaXtaC6O1LbPh1n8njGTeE6mObQ56eA3tDV1/a1ufm0u6RNKisj4vZPj1SXnuJOAy4IcRcUnD/f8g6Q5JT0p6kmq9NtUmQ15vCeDHaH3bblqGMPoNVZf8oHVMs5jqQPSgV5f7WvEc1e7IoFc1PhgRV0fEO6h6CHdTvUmHq2ewpkUt1jQS36Gqa7uI+AvgZEDDPGedp0wlbUR1HOYc4DRJm42gnhuB91Idt1pUbh8BTKU6IzrietZgXet/tfUpabX12cK8mpn3SlYPl3bm8eXy/DeV9XkYw6/PQd+kOqzw8plCSa+h2maPpjpssClwZ0Obw9W62uuVtCHV3kvt23bXwyginqI6XvJtSQdJ2kDSJEnvlPS1MtnFwCmSpkuaVqa/sMVZ3gHsKenVkjah6oYCL39KHVhWwItUu3ur1tDGVcDrJH1Q0kRJHwB2oOoZ1G1jqg3w2dJr+6chjz9CdXxjJM4C5kTER4FfUB3vAEDSaZJuWMdzb6Ta8G8qt28ot29u6O0NNdIa17X+fwe8UdJOktanOq7SzrzWNO/jJW1TQvvLVMfFOnV2dmOq7ewpSTOAf27mSZL+kar3eWhENG6jG1IFzkCZ7kiqntGgR4CtJE1eS9MXA0eW5bke1eudXQ4J1KrrYQQQEd+gusboFKqF+DDVBv3TMskXgTlUZyN+D9xW7mtlXtcCl5a2bmX1AOkrdSymOpOwF3/+ZiciHgMOoDqD9xjVGaEDImJZKzWN0KepDhY/Q/UJeOmQx08Dzi9d9PcP15ikA6lOIgy+zk8Bu0g6tNzemuqs4NrcSPWGGgyjm6l6Kjet9Rnwb1Th8qSkTw9XI+tY/xFxD9UB7l9RHRsZel3aOcAOZV4/ZeTOpToDeBPV2dUXqK5b65QvUB0sforqg+DyJp93CFXILpb0bPk5OSLmAt+g2uN4BHgTq6+/64C7gKWS/mx7jep6ps8DP6E6W/ta4OBWXthIpbno0XKSdAewbwlgs9o4jMwshRS7aWZmDiMzS8FhZGYpOIzMLIVR/S9jTd4oNGUk19M1b6dtX1lLu7ZmzV6V1wqfUhk/HnpwAcuWLWtqcxndMJqyGeu9ralrukbs5v88upZ2AVbVeMaxT3W+revT11df3atWjd04qrPyGhc5L9W0zPfcvdl/ifNumpkl4TAysxQcRmaWgsPIzFJwGJlZCg4jM0uhrTCStL+kP0iaL+mkThVlZr2n5TCSNIFqZIB3Un2x2CGSduhUYWbWW9rpGe0KzC9fVL6c6ovkOzHOmZn1oHbCaAarfxH5Qlb/0m4zs6bV/u8gko6iGkwP1p9a9+zMbIxqp2e0iOr7kQdtxRpGEIiIWRHRHxH9mtyREU3MbBxqJ4xuAbYroyZMpvrS7is6U5aZ9ZqWd9MiYqWko6mGQ55ANQrlmkZfNTMbVlvHjMpQ0ld1qBYz62G+AtvMUnAYmVkKDiMzS8FhZGYpOIzMLAWHkZmlMKqjg+y07StrG8XjFe85s5Z2AR7/+XG1ta0xOjpInepeJHUu86hxJJk6635++cpa2h3JyDruGZlZCg4jM0vBYWRmKTiMzCwFh5GZpeAwMrMUHEZmloLDyMxScBiZWQoOIzNLwWFkZik4jMwsBYeRmaXgMDKzFBxGZpaCw8jMUnAYmVkKDiMzS8FhZGYpOIzMLAWHkZml4DAysxRGdagigLoGcnniyuNrahmm7n1KbW0/fv3ptbVd46g59PXVOdxPbU0D9Q+FNBZtPGVSLe1OGMHCds/IzFJwGJlZCg4jM0vBYWRmKTiMzCwFh5GZpeAwMrMUWg4jSVtLul7SXEl3STq2k4WZWW9p56LHlcAJEXGbpI2BWyVdGxFzO1SbmfWQlntGEbEkIm4rfz8DzANmdKowM+stHTlmJGkmsDMwuxPtmVnvaTuMJG0E/AQ4LiKeXsPjR0maI2nOsmUD7c7OzMaptsJI0iSqILooIi5f0zQRMSsi+iOif9q06e3MzszGsXbOpgk4B5gXEWd0riQz60Xt9Iz2AA4H9pF0R/l5V4fqMrMe0/Kp/Yi4GfA3w5hZR/gKbDNLwWFkZik4jMwsBYeRmaXgMDKzFBxGZpbCqA9VVOMIN7WpczihzWocBumx679YW9s2+qLGMZyUYPwm94zMLAWHkZml4DAysxQcRmaWgsPIzFJwGJlZCg4jM0vBYWRmKTiMzCwFh5GZpeAwMrMUHEZmloLDyMxScBiZWQoOIzNLwWFkZik4jMwsBYeRmaXgMDKzFBxGZpaCw8jMUnAYmVkKozpUkcgxJMpI1Vnz4zfUN5zQ1fOW1tb2/jtsUVvbY3ATedlY3L6zcM/IzFJwGJlZCg4jM0vBYWRmKTiMzCwFh5GZpeAwMrMU2g4jSRMk3S7pyk4UZGa9qRM9o2OBeR1ox8x6WFthJGkr4N3A2Z0px8x6Vbs9ozOBE4FVHajFzHpYy2Ek6QDg0Yi4dZjpjpI0R9KcgWUDrc7OzMa5dnpGewDvkbQAuATYR9KFQyeKiFkR0R8R/dOnTW9jdmY2nrUcRhHx2YjYKiJmAgcD10XEYR2rzMx6iq8zMrMUOvJ9RhFxA3BDJ9oys97knpGZpeAwMrMUHEZmloLDyMxScBiZWQoOIzNLYVSHKrLR9bdveFVtbU/d/6u1tf34f51YW9t1e2H5S7W1PXlifX2Hvr7uD7HknpGZpeAwMrMUHEZmloLDyMxScBiZWQoOIzNLwWFkZik4jMwsBYeRmaXgMDKzFBxGZpaCw8jMUnAYmVkKDiMzS8FhZGYpOIzMLAWHkZml4DAysxQcRmaWgsPIzFJwGJlZCg4jM0vBYWRmKXjctC6LqLHt+prmiV9+pra2p+71udraBnjixi/V1vZ4H9usTu4ZmVkKDiMzS8FhZGYpOIzMLAWHkZml4DAysxTaCiNJm0q6TNLdkuZJemunCjOz3tLudUZnAb+MiPdKmgxs0IGazKwHtRxGkjYB9gQ+BBARy4HlnSnLzHpNO7tp2wADwPcl3S7pbEkbdqguM+sx7YTRRGAX4DsRsTPwHHDS0IkkHSVpjqQ5A8sG2pidmY1n7YTRQmBhRMwuty+jCqfVRMSsiOiPiP7p06a3MTszG89aDqOIWAo8LGn7cte+wNyOVGVmPafds2nHABeVM2n3A0e2X5KZ9aK2wigi7gD6O1SLmfUwX4FtZik4jMwsBYeRmaXgMDKzFBxGZpaCw8jMUnAYmVkKHqqoy8b78DOtqHMoIYCpbzm6trafuOVbtbU93rlnZGYpOIzMLAWHkZml4DAysxQcRmaWgsPIzFJwGJlZCg4jM0vBYWRmKTiMzCwFh5GZpeAwMrMUHEZmloLDyMxScBiZWQoOIzNLwWFkZik4jMwsBYeRmaXgMDKzFBxGZpaCw8jMUhjVoYoCWPnSqlra7tPYHPInamy7zlGQlq+sZz1C/euyzuGENjv43NrafvySD9fW9oqa1udItm/3jMwsBYeRmaXgMDKzFBxGZpaCw8jMUnAYmVkKbYWRpOMl3SXpTkkXS1q/U4WZWW9pOYwkzQA+CfRHxI7ABODgThVmZr2l3d20icAUSROBDYDF7ZdkZr2o5TCKiEXA14GHgCXAUxFxTacKM7Pe0s5u2lTgQGAbYEtgQ0mHrWG6oyTNkTRn2cBA65Wa2bjWzm7afsADETEQESuAy4Hdh04UEbMioj8i+qdNn97G7MxsPGsnjB4CdpO0gSQB+wLzOlOWmfWado4ZzQYuA24Dfl/amtWhusysx7T1FSIRcSpwaodqMbMe5iuwzSwFh5GZpeAwMrMUHEZmloLDyMxScBiZWQoOIzNLYVSHKhIwcYLzr1FEfYMVqcYhf9abNKG2tseyOocTmvrXx9bW9hOzz6ql3ZFsgU4GM0vBYWRmKTiMzCwFh5GZpeAwMrMUHEZmloLDyMxScBiZWQoOIzNLwWFkZik4jMwsBYeRmaXgMDKzFBxGZpaCw8jMUnAYmVkKDiMzS8FhZGYpOIzMLAWHkZml4DAysxQcRmaWwqgOVRTAypdW1dL2CyvqaRdgo/XrW0x1Dic0Vq1aVd/wTQB9ffUt8+Ur69sO6xpOCGDqe2fV0u6L9w00Pa17RmaWgsPIzFJwGJlZCg4jM0vBYWRmKTiMzCyFYcNI0rmSHpV0Z8N9m0m6VtK95ffUess0s/GumZ7RecD+Q+47Cfh1RGwH/LrcNjNr2bBhFBE3AY8PuftA4Pzy9/nAQR2uy8x6TKvHjDaPiCXl76XA5h2qx8x6VNsHsCMiqP7TY40kHSVpjqQ5ywaavzTczHpLq2H0iKQtAMrvR9c2YUTMioj+iOifNn16i7Mzs/Gu1TC6Ajii/H0E8LPOlGNmvaqZU/sXA78Btpe0UNJHgK8A75B0L7BfuW1m1rJhvxsjIg5Zy0P7drgWM+thvgLbzFJwGJlZCg4jM0vBYWRmKTiMzCwFh5GZpeAwMrMUVP1r2SjNTBoAHmxy8mnAshrLqctYrRvGbu2ue3SNpO7XRERT/wc2qmE0EpLmRER/t+sYqbFaN4zd2l336Kqrbu+mmVkKDiMzSyFzGNUz3m79xmrdMHZrd92jq5a60x4zMrPekrlnZGY9JGUYSdpf0h8kzZc0JkYekbS1pOslzZV0l6Rju13TSEiaIOl2SVd2u5ZmSdpU0mWS7pY0T9Jbu11TMyQdX7aROyVdLGn9bte0NqM5VFm6MJI0Afg28E5gB+AQSTt0t6qmrAROiIgdgN2AT4yRugcdC8zrdhEjdBbwy4h4PfBmxkD9kmYAnwT6I2JHYAJwcHerWqfzGKWhytKFEbArMD8i7o+I5cAlVEMjpRYRSyLitvL3M1RvjBndrao5krYC3g2c3e1amiVpE2BP4ByAiFgeEU92t6qmTQSmSJoIbAAs7nI9azWaQ5VlDKMZwMMNtxcyRt7UgyTNBHYGZne3kqadCZwIrOp2ISOwDTAAfL/sXp4tacNuFzWciFgEfB14CFgCPBUR13S3qhGrZaiyjGE0pknaCPgJcFxEPN3teoYj6QDg0Yi4tdu1jNBEYBfgOxGxM/AcY2Bk43J85UCqMN0S2FDSYd2tqnXDDVU2EhnDaBGwdcPtrcp96UmaRBVEF0XE5d2up0l7AO+RtIBql3gfSRd2t6SmLAQWRsRg7/MyqnDKbj/ggYgYiIgVwOXA7l2uaaSaHqpsJDKG0S3AdpK2kTSZ6uDeFV2uaViSRHX8Yl5EnNHtepoVEZ+NiK0iYibVsr4uItJ/UkfEUuBhSduXu/YF5naxpGY9BOwmaYOyzezLGDjwPkQtQ5UNOzrIaIuIlZKOBq6mOtNwbkTc1eWymrEHcDjwe0l3lPtOjoiruljTeHcMcFH50LofOLLL9QwrImZLugy4jeoM7O0kvhK7DFW2NzBN0kLgVKqhyX5Uhi17EHh/R+blK7DNLIOMu2lm1oMcRmaWgsPIzFJwGJlZCg4jM0vBYWRmKTiMzCwFh5GZpfD/qTWbm0trk2EAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 720x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "CLASSES_LIST = [cls.replace('\\n', '') for cls in CLASSES_LIST]\n",
    "class_names = np.unique(CLASSES_LIST)\n",
    "conf_mat = confusion_matrix(y_test, y_predicted)\n",
    "plt.figure(figsize=(10,10))\n",
    "plt.subplot(121)\n",
    "plot_confusion_matrix(conf_mat, class_names, title='Confusion matrix, without normalization')\n",
    "plt.subplot(122)\n",
    "plot_confusion_matrix(conf_mat, class_names, normalize=True, title='Normalized confusion matrix')\n",
    "print(class_names)\n",
    "print()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
